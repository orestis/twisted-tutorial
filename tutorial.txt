================
Twisted Tutorial
================

Network I/O 101
===============

Twisted is a library that can help you easily build networked applications in Python. While Twisted manages to abstract away most of the low-level network details, having at least a high-level understanding of network I/O will be very helpful.

At the very basic level, when you connect two processes using a mechanism that allows them to exchange data, you have networked them. It helps imagining two physical machines connected via a piece wire (FOOTNOTE: this metaphor doesn't stand for some mechanisms like UDP, but let's ignore that for now).

Once two machines are connected via a piece of wire, they can start using it. A single machine can write data at its end of the wire, and after some time it will arrive at the other end of the wire. Also, at any time data may arrive on the same end of the wire.

Event-driven programming
------------------------

We've already found one complication of network programming - data may arrive at any time. So some kind of mechanism must be in place in order to read the data and forward it to interested parties.

This is a form of event-driven programming, similar to GUI programming. GUI programs wait for a user to generate events such as "mouse clicked" or "key pressed" and will run specific methods to handle those events. When doing network programming, the events are streams of bytes arriving at your end of the wire.

The usual way to deal with events arrinving at any possible time is to have a constant running loop that will periodically check if there is a new event and forward it to whoever might be listening. In GUI programs the OS maintains a queue of events and your program will have a UI loop that pulls events off this queue.

Blocking I/O
------------

Unfortunately, network programs have one extra bit of complication. I f you try to read data off a socket (that's the end of the wire) that has no data in it, your program will suspend execution until some data arrives. For small programs that just need to do one thing, this is not a problem. However, when you have a long-running process, such a web server, that needs to stay responsive to other clients, this becomes an issue.

The usual way of avoiding suspening execution, or "blocking", is to put independent socket operations in different threads or even processes. This way, one can have a central service that just handles new connections, but the actual data back-and-forth happens in parallel. 

This approach, while completely correct and proven over the years, has some drawbacks:

* Every thread or process launched will consume some amount of memory. This means that the number of concurrent connections is limited by the available memory size.
* Writing large multi-threaded programs is hard. Avoiding starvation, deadlocks, guarding access to shared data with locks, synchronisation etc is very hard to get right and even harder to debug.
* Writing multi-process programs means that you have to use some kind of inter-process communication to pass data back and forth, which has a certain overhead.

Non-blocking I/O
----------------

The alternative approach is to open the socket in a non-blocking mode. This way, before you commit to read or write to a socket, you can check to see if it is ready. If it is, the OS guarantees that the operation will not block. If it isn't, you just check again a bit later. 

This sounds like a very good solution, and indeed you can implement it yourself using a good socket library. Unfortunately, there are a lot of things that need to be done just in the right way to ensure that no network operations will ever block, and if you need to support multiple platforms then there are subtle edge cases you need to worry about.

Fortunately, Twisted has solved all those problems and will give you non-blocking network I/O on most major platforms for free, leaving you free to focus on your actual application instead of worrying about low-level network details (FOOTNOTE: All abstractions are leaky. An understanding of the basics of networks can be very beneficial). Twisted provides an event loop that will forward data arriving from the network to interested handlers, and will also take care of sending data over the network to remote machines. This event loop all runs in a single thread, removing any reason to worry about synchronising data access or any other threading issues.

My first server
===============

Let's see an actual example of this. We'll write a server that listens on a TCP port, allows multiple clients to connect at the same time, and will print all data to its standard output.

First we need to setup the event loop. In Twisted we do this by using a global object called "reactor":

..code:
    from twisted.internet import reactor
    reactor.run()

When you run the snippet above, you will see that your program goes into an infinite loop, because the reactor loop has taken over. You will need to kill your process with ctrl-c to get your shell back.

Defining behaviour
------------------

The next step is to install a network event handler. The first event we care about is someone connecting to our server. When this happens, we should create a separate instance of a class for each connection, to ensure client-specific state is separated (if we were doing this with threads, we'd use a threadlocal object. However Twisted is single-threaded, so we can use plain Object Oriented Programming approaches). The classes that we'll be creating must implement twisted.internet.interfaces.IProtocol.

The design pattern of something that creates instances is called a Factory, so our "connection made" handler will be a twisted.internet.interfaces.IProtocolFactory. 

Twisted fortunately has concrete implementations of those interfaces. So we will be using twisted.internet.protocol.ServerFactory (since we are building a server) and we'll subclass twisted.internet.protocol.Protocol to provide our custom behaviour.

(FOOTNOTE: While Twisted has default implementations for those interfaces, you are free to implement your own should you ever need to. Just make sure you conform to the interface. It usually is a better idea to subclass BaseProtocol than to start from scratch.)

.. code: helloworld.py 1:10

So, at first we do the necessary imports. Then we define a very simple protocol, that will print whatever data arrives in its standard output. Then we define a factory that on every connection will create instances of the HelloWorldProtocol. Note how none of this knows or cares of where the data comes from. Twisted will deal with creating instances of the protocol as new connections arrive, and will call 'dataReceived' whenever data becomes available.

(SIDENOTE: `dataReceived` will be called with arbitrary amounts of data. The protocol class is required to buffer incoming data and try to divide them in meaningful messages. The best way is to assume you will receive data one byte at a time. That said, Twisted has a lot of useful protocol subclasses that help with usual message formats such as line-separated, length prefixed etc. See `twisted.protocols` for a complete list.)

Listening on a port
-------------------

The final piece is installing the factory. Since we want a TCP server, we will attach it to a specific TCP port. To do this, we need to use something called an Endpoint.

Endpoints are a bit like our end of the wire. You create an endpoint of a specific type - in our case a TCP endpoint - with transport-specific paramters - in our case, a port number. Then you attach a factory instance to it.

.. code: helloworld.py 11:17

So, we start again with necessary imports. We then create an endpoint instance and a factory instance and bind them together. Finally we start the reactor loop.

(SIDENOTE: While the reactor is used like a global object, new code is advised to accept reactor as a parameter. This allows for much better testing, passing special-behavior reactors, and in the future will allow for multiple reactors running together)

(SIDENOTE: Endpoints are a fairly recent (in Twisted time) API. If you have an older version of Twisted, you will need to use the equivalent but less flexible approach of doing `reactor.listenTCP(8000, factory)`.)

Trying it out
-------------

Try running the complete listing on a shell (watch out for firewalls blocking access!) and from another shell do `telnet 127.0.0.1 8000`. Start typing data into telnet (telnet will only send them across the wire when you hit enter - do not rely on this behaviour!). Kill the telnet process by sending the escape character (usually `ctrl-]`) followed by `ctrl-c`. Try starting multiple parallel telnet sessions. You'll find that the server quite happily accepts multiple connections.
`

Sending data back to the client
===============================

We've already made a huge step - we wrote a non-blocking server that accepts data from multiple clients in only a few lines of code. While this may be useful if you want to do things like logging, at most cases you'd want to send something back to the client.

The way to send data to the client is by using the `transport` attribute on our protocol instance. This is an implementation of `twisted.internet.interfaces.ITransport` we can think about it as the end of the wire you write data into. This happens by using `write` or `writeSequence`.

So, let's extend our server to make it send every piece of data it receives back to the client, but uppercased! We do this in our `dataReceived` handler.

..code: upperserver.py 3:9

So just like that we can send data back to the client.

Something a bit more useful
===========================

So far we've covered the very basics of writing a server. However, even with this small knowledge we can go very very far. We will now write an almost-compliant memcached server that you can use on your webserver with any compatible memcached client.

The basic stuff
---------------

At its core, memcached is a key-value store. So our implementation will be based on a plain python dictionary.

.. code: memcached1.py

Note we are ignoring the timeout value for simplicity. By the end of this tutorial we'll have built a truly compliant memcached server.

Sharing state
-------------

Memcached is useful because multiple clients can connect to it and shared the same data. Therefore, we will need to create a single instance of `Memcached` and share it between different protocol instances. We do this by passing a reference to it when we build a protocol instance in our factory.

.. code: memcached_server.py 53:63

Our ServerFactory now has an `__init__` method, and we also override the `buildProtocol` method to create a protocol instance with specific arguments.

(SIDENOTE: You will find a lot of Twisted examples or code that uses a slightly different approach of relying on the default implementation of `twisted.internet.protocol.Factory` that sets a `factory` attribute on all protocol instances it creates, pointing to itself. This way a protocol instance can access shared state by doing `self.factory.store`. While this is normal python usage, newcomers tend to be confused and assume some magic is going on. It is recommended that a Protocol class accepts any dependencies as arguments for code clarity and of course testability.)

Specification
-------------

This factory will not change throughout the tutorial. Let's see the protocol next. We should start at the memcached protocol spefication (actually, a subset of it - get and set commands).

A clients sends a 'get' command by sending the following string of bytes: `get <key>\r\n` where the key is a string. A 'set' command is initiated by first sending `set <key> <flags> <timeout> <length>\r\n` where flags is an integer that can be retrieved later, timeout is the number of seconds this entry will stay around and length is the length of the data that will represent the value. Then the client sends <length>number of bytes, followed by `\r\n`. Keys may not contain spaces or newlines, and must be less than 250 characters.

Example:

.. pre:

    set example_key 0 3600 13\r\n
    example_value\r\n

(line break added for clarity)

Decoding messages
-----------------

Remember how `dataReceived` is called with any data that is available and it is the protocol's job to decode that into actual messages? In this case, it seems that splitting at lines is important. We could do it ourselves by buffering the data and looking for new line delimiters, but this a so frequent example that Twisted has already support for it, in the form of `twisted.protocols.LineReceiver`. This is a Protocol subclass that instead of dataReceived exposes `lineReceived` method that will only be called with complete lines (without the delimiter).

.. code: memcached_server.py 1:15

Much easier - now lineReceived just parses the arguments and delegates ot other methods to do the actual work.

The spec for responding to a `get` request is straightforward. If the requested key is in the store, we respond with `VALUE <key> <flags> <length>\r\n`, then the raw data followed by '\r\n' then `END\r\n`. If the key is not in the store, just send `END\r\n`.

.. code: memcached_server.py 16:25

So, this is exactly what we do. We use the `sendLine` convenience method of `basic.LineReceiver` when we need to have `\r\n` delimiters, and `self.transport.write` when we need to send raw data.

The spec for responding to a `set` request is a bit more involved. This is because the client will send `set <key> <flags> <timeout> <length>\r\n` followed by `length` bytes of data followed by `\r\n`. Since the raw data *can* contain newlines or indeed any binary data, we cannot use `lineReceived` as it will try to parse them. Fortunately `basic.LineReceiver` has a way to do just that, called `setRawMode`. Calling this will deactivate the line parsing behaviour and data will be delivered instead using the `rawDataReceived` method. When we want to switch the line parsing mode on again, we'll call `setLineMode` passing in any superfluous data we might have received.

When the server has managed to store the value, it will send `STORED` back.

(SIDENOTE: This kind of behaviour is very usual when designing or implementing protocols. Fortunately Twisted has already support for a lot of protocols in `twisted.protocols` and a lot of utility class ready for subclassing in `twisted.protocols.basic`.)

(TODO: find if the client is allowed to send new requests if a `STORED` is pending)

..code: memcached_server.py 27:43

So, when `handle_set` is called the first thing it does is initialise some instance variables that will be passed on to the actual store later on (if this seems a bit unsafe, remember that this protocol instance will handle data only from a single client connection), and then goes into raw data mode.

`rawDataReceived` is then called repeatedly, buffering the received data. Once `<length>` amount of bytes has been received, plus the newline required by the spec, we store everything in the store, reply with 'STORED\r\n' and switch line mode back on. Since we might have received more data than we can handle (for example, the start of a new command) we need to pass that in `setLineMode` so that the line parsing mechanism can pass them into the next call of `lineReceived`.

(SIDENOTE: Notice that so far everything we have been doing for implementing the protocol is not Twisted specific and with a bit of API massaging it could be reused with any similar networking library. In fact, there is a PEP being written currently that hopefully be in Python 3.4 that will provide a library-agnostic API that various protocols can provide so that they can be used with any networking library that supports the Python Async API.)

..code: memcached_server.py 58:64


(TODO: make sure we haven't done anything stupid and very incompatible in the above code)

(TODO: why oh why aren't those classes new-style objects? How is someone supposed to know if something has an __init__ or not?)

Finally we just instantiate an endpoint and a factory and bind them together. We are using the memcached default port, 11211. Run this example and have a play with it using any memcached-compatible client and see it behaves quite as you expected (at least when using only the get and set commands). (WARNING: This implementation is not suitable for production systems and certainly not supposed to be exposed to untrusted clients)

(TODO: perhaps we should point people to an actual production implementation here?)

Adding timeouts
---------------

The implementation, apart from its gaping security holes, has another problem - it ignores the timeout setting completely. This will mean that at some point your server will run out of memory and even worse, clients would expect things to be expiring and they would receive incorrect results. Let's fix that.

If you have a function that needs to be called some time in the future, `reactor.callLater` does this for you. It works like so:

..code:

    from twisted.internet import reactor

    def print_it(s):
        print s
    reactor.callLater(5, print_it, "5 seconds passed")
    reactor.callLater(10, print_it, "10 seconds passed")
    reactor.callLater(11, reactor.stop)

    reactor.run()

If you run the above snippet you'll see that it will print two lines after 5 and 10 seconds respectively, and after 11 seconds it will stop and exit to the command line.

(SIDENOTE: Careful readers may have read that reactor also has a `listenTCP` method, and we now also show `callLater`. The global reactor instance actually implements numerous interfaces, all found in `twisted.internet.reactor`)

When scheduling a call into the future, it is useful to be able to retain a reference to it so you can cancel it or reschedule it. `callLater` returns an `IDelayedCall` instance that you can call `cancel`, `reset` or `delay` on.

..code: 

    def print_it(p):
        print p

    def abort(call):
        if call.active():
            print 'CANCELLING'
            call.cancel()

    delayedCall = reactor.callLater(5, print_it, 'HI')
    reactor.callLater(4, abort, delayedCall)
    reactor.callLater(6, reactor.stop)

    reactor.run()

Running the above snippet you will see how 'HI' is never printed because the call was cancelled. Note also that you can only call `cancel` on a call that is still active. Calling `cancel` on a call that has either been called or has been cancelled will raise an Exception.

So, in our case, we, will change our memcached store implementation to look like this:

..code: memcached2.py

When dealing with calls that will arrive later, we must take care that a left-over timeout will expire a key prematurely, so we cancel any timeouts that may or may not be pending before we schedule any new ones.

All we need to change to support timeouts is we import `Memcached` from `memcached2` instead of `memcached1`.

A summary
---------

So, in bullet form, here's key points covered so far:

* To do anything in Twisted, you need to start a reactor loop by doing `reactor.run()`
* To find a piece of wire to listen on, you need to instantiate an appropriate endpoint.
* To handle new connections, you need a protocol factory that will build protocol instances.
* Protocol instances only deal with a single connection and only live as long as that.
* It is your responsibility to deal with shared state by injecting it into the protocol instances you create. Subclass a server factory.
* Data will arrive in a protocol instance at arbitrary chunks. Test is with a byte at a time to make sure you are not making any false assumptions.
* Implementing protocols correctly is hard, try to reuse as much code as possible.
* To schedule a function call later in time, use `reactor.callLater` and keep a reference to the return value if you want to do something with it before it's called.












Asynchronous Programming 101
============================

So, we've found a way to deal with data coming from a socket in a non-blocking fashion, so we can use an event loop that will forward them to our handlers. However, since 





